{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial Landmark Detection",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP80We/N1r1vWOG6V6395eB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parrisem/Facial-Landmark-Detection/blob/main/Facial_Landmark_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCwD6qiJYw-G"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac4tYe_rY0YD"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.callbacks import  History\n",
        "from sklearn.cluster import KMeans\n",
        "import skimage\n",
        "from skimage import transform, util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyTstBJyX62W"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMwPNCWPakbt"
      },
      "source": [
        "!wget \"http://users.sussex.ac.uk/~is321/training_images.npz\" -O training_images.npz\n",
        "# The test images (without points)\n",
        "!wget \"http://users.sussex.ac.uk/~is321/test_images.npz\" -O test_images.npz\n",
        "# The example images are here\n",
        "!wget \"http://users.sussex.ac.uk/~is321/examples.npz\" -O examples.npz\n",
        "\n",
        "# Load the data using np.load\n",
        "data = np.load('training_images.npz', allow_pickle=True)\n",
        "test = np.load('test_images.npz', allow_pickle=True)\n",
        "examples = np.load('examples.npz', allow_pickle=True)\n",
        "\n",
        "# Extract the images and points\n",
        "images = data['images']\n",
        "pts = data['points']\n",
        "test_imgs = test['images']\n",
        "example_imgs = examples['images']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow3XvFLhbNhg"
      },
      "source": [
        "# Visualising the images and points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaI9Ndn7cVsH"
      },
      "source": [
        "# Displays some of the images from the data\n",
        "print(images.shape, pts.shape)\n",
        "def visualise_pts(img, pts):\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.imshow(img)\n",
        "  plt.plot(pts[:, 0], pts[:, 1], '+r')\n",
        "  plt.show()\n",
        "\n",
        "for i in range(3):\n",
        "  idx = np.random.randint(0, images.shape[0])\n",
        "  visualise_pts(images[idx, ...], pts[idx, ...])\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcke2OcwZQQP"
      },
      "source": [
        "# Calculating Prediction Error and exporting results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-w6_iFxZZLo"
      },
      "source": [
        "def euclid_dist(pred_pts, gt_pts):\n",
        "  \"\"\"\n",
        "  Calculate the euclidean distance between pairs of points\n",
        "  :param pred_pts: The predicted points\n",
        "  :param gt_pts: The ground truth points\n",
        "  :return: An array of shape (no_points,) containing the distance of each predicted point from the ground truth\n",
        "  \"\"\"\n",
        "  import numpy as np\n",
        "  pred_pts = np.reshape(pred_pts, (-1, 2))\n",
        "  gt_pts = np.reshape(gt_pts, (-1, 2))\n",
        "  return np.sqrt(np.sum(np.square(pred_pts - gt_pts), axis=-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwLgqqMUZdqh"
      },
      "source": [
        "def save_as_csv(points, location = '.'):\n",
        "  \"\"\"\n",
        "  Save the points out as a .csv file\n",
        "  :param points: numpy array of shape (no_image, no_points, 2) to be saved\n",
        "  :param location: Directory to save results.csv in. Default to current working directory\n",
        "  \"\"\"\n",
        "  np.savetxt(location + '/results.csv', np.reshape(points, (points.shape[0], -1)), delimiter=',')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfNnCdR1ag54"
      },
      "source": [
        "# Pre-processing Images and Points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wiNJL5ibA5G"
      },
      "source": [
        "# Making the training and testing images grayscale\n",
        "copy_train_imgs = np.copy(images)\n",
        "copy_train_pts = np.copy(pts)\n",
        "copy_test_imgs = np.copy(test_imgs)\n",
        "\n",
        "print(\"Training images:\",copy_train_imgs.shape)\n",
        "print(\"Training points:\",copy_train_pts.shape)\n",
        "print(\"Testing images:\",copy_test_imgs.shape)\n",
        "\n",
        "grey_train_imgs = []\n",
        "grey_test_imgs = []\n",
        "\n",
        "# training images\n",
        "for i in range(0,copy_train_imgs.shape[0]):\n",
        "  grey_train_imgs.append(cv2.cvtColor(copy_train_imgs[i], cv2.COLOR_BGR2GRAY))\n",
        "grey_train_imgs = np.array(grey_train_imgs)\n",
        "print(\"Grey training images:\",grey_train_imgs.shape)\n",
        "\n",
        "# testing images\n",
        "for i in range(0,copy_test_imgs.shape[0]):\n",
        "  grey_test_imgs.append(cv2.cvtColor(copy_test_imgs[i],cv2.COLOR_BGR2GRAY))\n",
        "grey_test_imgs = np.array(grey_test_imgs)\n",
        "print(\"Grey testing images:\",grey_test_imgs.shape)\n",
        "\n",
        "\n",
        "plt.imshow(grey_train_imgs[5])\n",
        "plt.plot(copy_train_pts[5][:,0],copy_train_pts[5][:,1],'+r')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-NK9ZFKgFUq"
      },
      "source": [
        "# Rescaling the training and testing images and training points.\n",
        "resc_gray_imgs = []\n",
        "resc_pts = []\n",
        "resc_gray_test_imgs = []\n",
        "\n",
        "for i in range(0,grey_train_imgs.shape[0]):\n",
        "  resc_gray_imgs.append(cv2.resize(grey_train_imgs[i],(100,100)))\n",
        "for i in range(0,copy_train_pts.shape[0]):\n",
        "  resc_pts.append(copy_train_pts[i]*[100/250,100/250])\n",
        "\n",
        "for i in range(0,grey_test_imgs.shape[0]):\n",
        "  resc_gray_test_imgs.append(cv2.resize(grey_test_imgs[i],(100,100)))\n",
        "\n",
        "resc_gray_imgs = np.array(resc_gray_imgs)\n",
        "resc_pts = np.array(resc_pts)\n",
        "resc_gray_test_imgs = np.array(resc_gray_test_imgs)\n",
        "\n",
        "print(\"Rescaled grey image:\",resc_gray_imgs.shape)\n",
        "print(\"Rescaled grey image points:\",resc_pts.shape)\n",
        "print(\"Rescaled grey test image:\",resc_gray_test_imgs.shape)\n",
        "\n",
        "plt. imshow(resc_gray_imgs[5])\n",
        "plt.plot(resc_pts[5][:,0], resc_pts[5][:,1],'+r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y-RrLG-IlMS"
      },
      "source": [
        "# normalise training and testing image arrays.\n",
        "norm_train_imgs = resc_gray_imgs/255\n",
        "norm_train_pts = resc_pts/100-1\n",
        "norm_test_imgs = resc_gray_test_imgs/255\n",
        "\n",
        "plt.imshow(norm_train_imgs[5])\n",
        "plt.plot((norm_train_pts[5][:,0]+1)*100,(norm_train_pts[5][:,1]+1)*100,'+r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLKt-uvMnRXr"
      },
      "source": [
        "# CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT9d_cYzoKeB"
      },
      "source": [
        "history = History()\n",
        "train_imgs_x = norm_train_imgs.reshape(norm_train_imgs.shape[0],100,100,1)\n",
        "train_imgs_y = norm_train_pts.reshape(norm_train_pts.shape[0],-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpu49CPbnT7b"
      },
      "source": [
        "# first model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu', strides=1, input_shape=(100, 100, 1)))\n",
        "model.add(MaxPooling2D(pool_size =(2,2)))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), padding='same', strides=1, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size =(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same',strides=1, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size =(2,2)))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), padding='same',strides=1, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size =(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(84))\n",
        "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0O8vTJywI1j"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKON6VTvwLsb"
      },
      "source": [
        "history = model.fit(train_imgs_x, train_imgs_y, validation_split=0.3, batch_size=50, shuffle=True, epochs=150, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gBEJbeCw6DM"
      },
      "source": [
        "# epochs 100\n",
        "# loss plot\n",
        "plt.figure(figsize=(17,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.suptitle('Original Data', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.plot(history.history['loss'], color='r', label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], color='b', label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.plot(history.history['accuracy'], color='r', label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], color='b', label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSxs5N1_rq5c"
      },
      "source": [
        "#epochs 150\n",
        "# loss plot\n",
        "plt.figure(figsize=(17,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.suptitle('Original Data', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.plot(history.history['loss'], color='r', label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], color='b', label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.plot(history.history['accuracy'], color='r', label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], color='b', label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EffadGyajGD2"
      },
      "source": [
        "# Predicting and saving the test images points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ZhUFNYjhGY"
      },
      "source": [
        "pts_test = model.predict(norm_test_imgs.reshape(norm_test_imgs.shape[0], 100,100,1))\n",
        "test_pts = pts_test.reshape(pts_test.shape[0],42,-1)\n",
        "save_as_csv(test_pts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4n_9qW4j_XT"
      },
      "source": [
        "#vizualise some of the test images with thier predicted points, epochs 100\n",
        "plt.imshow(norm_test_imgs[444])\n",
        "plt.plot((test_pts[444][:,0]+1)*100,(test_pts[444][:,1]+1)*100, '+r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrzlbqobueaX"
      },
      "source": [
        "#vizualise some of the test images with thier predicted points, epochs 150\n",
        "plt.imshow(norm_test_imgs[300])\n",
        "plt.plot((test_pts[300][:,0]+1)*100,(test_pts[300][:,1]+1)*100, '+r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33xH-N7li1Me"
      },
      "source": [
        "# Augmenting the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FXDXVXii9Em"
      },
      "source": [
        "# Rotating the images and points\n",
        "def rotate_img_pts(img,pts):\n",
        "   \"\"\"\n",
        "  Rotate the images and their points\n",
        "  :param img: The image\n",
        "  :param pts: The points\n",
        "  :return: Tuple of the rotated images and the rotated points\n",
        "  \"\"\"\n",
        "  new_img = np.copy(img)\n",
        "  rot_pts = np.copy(pts)\n",
        "  rot_img = skimage.transform.rotate(new_img, angle=90)\n",
        "  for i in range(0,42):\n",
        "    rot_pts = np.rot90(pts,2)\n",
        "\n",
        "  return rot_img,rot_pts\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVk6t6Bfmq-O"
      },
      "source": [
        "rot_train_imgs = []\n",
        "rot_train_pts = []\n",
        "\n",
        "for i in range(0,norm_train_imgs.shape[0]):\n",
        "  rotated_imgs,rotated_pts = rotate_img_pts(norm_train_imgs[i],norm_train_pts[i])\n",
        "  rot_train_imgs.append(rotated_imgs)\n",
        "  rot_train_pts.append(rotated_pts)\n",
        "\n",
        "rot_train_imgs = np.array(rot_train_imgs)\n",
        "rot_train_pts = np.array(rot_train_pts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtMelGP6tdnc"
      },
      "source": [
        "plt.imshow(rot_train_imgs[3])\n",
        "plt.plot((rot_train_pts[3][:,0]+1)*100,(rot_train_pts[3][:,1]+1)*100,'+r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xIJ7Ax5RTL2"
      },
      "source": [
        "new_training_imgs = np.concatenate((norm_train_imgs, rot_train_imgs))\n",
        "new_training_pts = np.concatenate((norm_train_pts, rot_train_pts))\n",
        "print(new_training_imgs.shape)\n",
        "print(new_training_pts.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMYnT4H9uPff"
      },
      "source": [
        "f_history = History()\n",
        "f_train_imgs_x = new_training_imgs.reshape(new_training_imgs.shape[0],100,100,1)\n",
        "f_train_imgs_y = new_training_pts.reshape(new_training_pts.shape[0],-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8x_Xq8t9c-X"
      },
      "source": [
        "# Building final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSYM_ft3uoN9"
      },
      "source": [
        "# final model\n",
        "\n",
        "f_model = Sequential()\n",
        "f_model.add(Conv2D(32, (3,3), activation='relu', strides=1, input_shape=(100, 100, 1)))\n",
        "f_model.add(MaxPooling2D(pool_size =(2,2)))\n",
        "\n",
        "f_model.add(Conv2D(64,(3,3), strides=1, activation='relu'))\n",
        "f_model.add(MaxPooling2D(pool_size =(2,2)))\n",
        "f_model.add(Conv2D(64, (3,3), strides=1, activation='relu'))\n",
        "f_model.add(MaxPooling2D(pool_size =(2,2)))\n",
        "\n",
        "f_model.add(Conv2D(128,(3,3), strides=1, activation='relu'))\n",
        "f_model.add(MaxPooling2D(pool_size =(2,2)))\n",
        "\n",
        "f_model.add(Flatten())\n",
        "f_model.add(Dense(512, activation='relu'))\n",
        "f_model.add(Dropout(0.2))\n",
        "\n",
        "f_model.add(Dense(84))\n",
        "f_model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
        "f_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hiNULvZ9g3C"
      },
      "source": [
        "# Training final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWp3QrcGM3wL"
      },
      "source": [
        "f_history = f_model.fit(f_train_imgs_x,f_train_imgs_y, validation_split=0.3, batch_size=50, shuffle=True, epochs=150, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS8MMVmYdMzn"
      },
      "source": [
        "# Epochs 100\n",
        "# loss plot\n",
        "plt.figure(figsize=(17,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.suptitle('Rotated Data', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.plot(f_history.history['loss'], color='r', label='Training Loss')\n",
        "plt.plot(f_history.history['val_loss'], color='b', label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.plot(f_history.history['accuracy'], color='r', label='Training Accuracy')\n",
        "plt.plot(f_history.history['val_accuracy'], color='b', label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1toK9yWr_pls"
      },
      "source": [
        "# Epochs 150\n",
        "# loss plot\n",
        "plt.figure(figsize=(17,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.suptitle('Rotated Data', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.plot(f_history.history['loss'], color='r', label='Training Loss')\n",
        "plt.plot(f_history.history['val_loss'], color='b', label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.plot(f_history.history['accuracy'], color='r', label='Training Accuracy')\n",
        "plt.plot(f_history.history['val_accuracy'], color='b', label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCjkptc19VBK"
      },
      "source": [
        "# Predicting and saving the test points for final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk_48CO0C4Gw"
      },
      "source": [
        "pts_test_2 = f_model.predict(norm_test_imgs.reshape(norm_test_imgs.shape[0], 100,100,1))\n",
        "test_pts_2 = pts_test_2.reshape(pts_test_2.shape[0],42,-1)\n",
        "save_as_csv(test_pts_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV0kwgp3D-i3"
      },
      "source": [
        "#vizualise some of the test images with thie predicted points, epochs 100\n",
        "plt.imshow(norm_test_imgs[300])\n",
        "plt.plot((test_pts_2[300][:,0]+1)*100,(test_pts_2[300][:,1]+1)*100,'+r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQV3PhztPjtz"
      },
      "source": [
        "#vizualise some of the test images with thie predicted points, epochs 150\n",
        "plt.imshow(norm_test_imgs[300])\n",
        "plt.plot((test_pts_2[300][:,0]+1)*100,(test_pts_2[300][:,1]+1)*100,'+r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNYPsCb3-3lh"
      },
      "source": [
        "# Calculating Prediction Error and exporting results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAE5aDfj_GXg"
      },
      "source": [
        "# Example 1\n",
        "ed = f_model.predict(f_train_imgs_x)\n",
        "ed = ed.reshape(ed.shape[0],42,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di6ncoY9EChd"
      },
      "source": [
        "plt.imshow(norm_train_imgs[1])\n",
        "plt.plot((norm_train_pts[1][:,0]+1)*100,(norm_train_pts[1][:,1]+1)*100,'+r')\n",
        "plt.show()\n",
        "\n",
        "euclid_dist((ed[1]+1)*100,(norm_train_pts[1]+1)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unDCtrxcEX4j"
      },
      "source": [
        "# Example 2\n",
        "plt.imshow(norm_train_imgs[7])\n",
        "plt.plot((norm_train_pts[7][:,0]+1)*100,(norm_train_pts[7][:,1]+1)*100,'+r')\n",
        "plt.show()\n",
        "\n",
        "euclid_dist((ed[7]+1)*100,(norm_train_pts[7]+1)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLn6O9v8EtAU"
      },
      "source": [
        "# Example 3\n",
        "plt.imshow(norm_train_imgs[133])\n",
        "plt.plot((norm_train_pts[133][:,0]+1)*100,(norm_train_pts[133][:,1]+1)*100,'+r')\n",
        "plt.show()\n",
        "\n",
        "euclid_dist((ed[133]+1)*100,(norm_train_pts[133]+1)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF8WHTKrxW_s"
      },
      "source": [
        "# Face Segmentation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkgLC0JNlxbC"
      },
      "source": [
        "def img_segmentation(img,pts):\n",
        "  \"\"\"\n",
        "  Fills the face in an image with colour using the points predicted by the model as its boundary\n",
        "  :param img: The image\n",
        "  :param pts: The predicted points\n",
        "  \"\"\"\n",
        "  seg_img = np.zeros((100,100), dtype=np.uint8)\n",
        "  bounds = pts\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "  fig.suptitle('BEFORE & AFTER')\n",
        "  cv2.fillPoly(seg_img, np.int32([bounds]), [255,255,255], lineType=4, shift=0)\n",
        "\n",
        "  ax2.imshow(seg_img)\n",
        "  ax1.imshow(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGrZ5mv6oKy8"
      },
      "source": [
        "# Testing final model on example images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrkvZWZrkhZw"
      },
      "source": [
        "# visualising the example images\n",
        "example_imgs.shape\n",
        "\n",
        "plt.imshow(example_imgs[1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loEltwyzsLQf"
      },
      "source": [
        "# Pre-processing example images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir6xo2vxsBBo"
      },
      "source": [
        "# pre-processing the example images like I did with the training and testing images\n",
        "\n",
        "gray_example_imgs = []\n",
        "resc_example_imgs = []\n",
        "\n",
        "# make grayscale\n",
        "for i in range(0,example_imgs.shape[0]):\n",
        "  gray_example_imgs.append(cv2.cvtColor(example_imgs[i],cv2.COLOR_BGR2GRAY))\n",
        "gray_example_imgs = np.array(gray_example_imgs)\n",
        "print(\"Grey example images:\",gray_example_imgs.shape)\n",
        "\n",
        "# resize\n",
        "for i in range(0,gray_example_imgs.shape[0]):\n",
        "  resc_example_imgs.append(cv2.resize(gray_example_imgs[i],(100,100)))\n",
        "resc_example_imgs = np.array(resc_example_imgs)\n",
        "print(\"Rescaled grey example images:\", resc_example_imgs.shape)\n",
        "plt.imshow(resc_example_imgs[1])\n",
        "\n",
        "# normalize\n",
        "norm_ex_imgs = resc_example_imgs/255\n",
        "print(\"Normalized grey, rescaled example images:\", norm_ex_imgs.shape)\n",
        "\n",
        "plt.imshow(norm_ex_imgs[1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GggMxZ9C6AJ"
      },
      "source": [
        "# Predicting and saving the points for example images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBX-QoTPulvz"
      },
      "source": [
        "example_predict_pts = f_model.predict(norm_ex_imgs.reshape(norm_ex_imgs.shape[0],100,100,1))\n",
        "ex_predict_pts = example_predict_pts.reshape(example_predict_pts.shape[0],42,2)\n",
        "save_as_csv(ex_predict_pts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NB1xHFku61P"
      },
      "source": [
        "# visualising the points on the image\n",
        "plt.imshow(norm_ex_imgs[1])\n",
        "plt.plot((ex_predict_pts[1][:,0]+1)*100,(ex_predict_pts[1][:,1]+1)*100,'+r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iT-OAN4gS7b"
      },
      "source": [
        "# visualising the points on the image\n",
        "plt.imshow(norm_ex_imgs[2])\n",
        "plt.plot((ex_predict_pts[2][:,0]+1)*100,(ex_predict_pts[2][:,1]+1)*100,'+r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL1gtQPOglwk"
      },
      "source": [
        "# visualising the points on the image\n",
        "plt.imshow(norm_ex_imgs[3])\n",
        "plt.plot((ex_predict_pts[3][:,0]+1)*100,(ex_predict_pts[3][:,1]+1)*100,'+r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIEcUoBxDqja"
      },
      "source": [
        "# Applying Face Segmentation on example images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YbVmJ39Dprd"
      },
      "source": [
        "img_seg(example_imgs[1],(ex_predict_pts[1]+1)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8trt1VQvhc7Q"
      },
      "source": [
        "img_seg(example_imgs[0],(ex_predict_pts[0]+1)*100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}